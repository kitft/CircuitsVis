{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CircuitsVis Demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup/Imports\n",
    "\n",
    "__Note:__ To run Jupyter directly within this repo, you may need to run `poetry run pip install jupyter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable python import reloading\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "from circuitsvis.attention import attention_patterns, attention_pattern\n",
    "from circuitsvis.activations import text_neuron_activations\n",
    "from circuitsvis.examples import hello\n",
    "from circuitsvis.tokens import colored_tokens\n",
    "from circuitsvis.topk_tokens import topk_tokens\n",
    "from circuitsvis.topk_samples import topk_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Built In Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Neuron Activations (single sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['Hi', ' and', ' welcome', ' to', ' the', ' Attention', ' Patterns', ' example']\n",
    "n_layers = 3\n",
    "n_neurons_per_layer = 4\n",
    "activations = np.random.normal(size=(len(tokens), n_layers, n_neurons_per_layer))\n",
    "activations = np.exp(activations) / np.exp(activations).sum(axis=0, keepdims=True) \n",
    "text_neuron_activations(tokens=tokens, activations=activations)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Neuron Activations (multiple samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [['Hi', ' and', ' welcome', ' to', ' the', ' Attention', ' Patterns', ' example'], ['This', ' is', ' another', ' example', ' of', ' colored', ' tokens'], ['And', ' here', ' another', ' example', ' of', ' colored', ' tokens', ' with', ' more', ' words.'], ['This', ' is', ' another', ' example', ' of', ' tokens.']]\n",
    "n_layers = 3\n",
    "n_neurons_per_layer = 4\n",
    "activations = []\n",
    "for sample in tokens:\n",
    "    sample_activations = np.random.normal(size=(len(sample), n_layers, n_neurons_per_layer)) * 5\n",
    "    activations.append(sample_activations)\n",
    "text_neuron_activations(tokens=tokens, activations=activations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention Pattern (single head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['Hi', ' and', ' welcome', ' to', ' the', ' Attention', ' Patterns', ' example']\n",
    "attention = np.tril(np.random.normal(loc=0.3, scale=0.2, size=(8,8)))\n",
    "attention_pattern(tokens=tokens, attention=attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['Hi', ' and', ' welcome', ' to', ' the', ' Attention', ' Patterns', ' example']\n",
    "attention = np.tril(np.random.normal(loc=0.3, scale=0.2, size=(12,8,8)))\n",
    "attention_patterns(tokens=tokens, attention=attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Colored Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['Hi', ' and', ' welcome', ' to', ' the', ' Colored', ' Tokens', ' example']\n",
    "values = np.random.normal(size=(len(tokens))).tolist()\n",
    "colored_tokens(tokens, values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topk Tokens Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [['Hi', ' and', ' welcome', ' to', ' the', ' Attention', ' Patterns', ' example'], ['This', ' is', ' another', ' example']]\n",
    "n_layers = 3\n",
    "n_neurons_per_layer = 25\n",
    "activations = []  # list of samples of shape (n_layers, n_tokens, n_neurons)\n",
    "for sample in tokens:\n",
    "    sample_activations = np.random.normal(size=(n_layers, len(sample), n_neurons_per_layer))\n",
    "    sample_activations = np.exp(sample_activations) / np.exp(sample_activations).sum(axis=1, keepdims=True)\n",
    "    activations.append(sample_activations)\n",
    "\n",
    "# Assume we have an arbitrary selection of layers\n",
    "layer_labels = [2, 7, 9]\n",
    "topk_tokens(tokens=tokens, activations=activations, max_k=7, first_dimension_name=\"Layer\", third_dimension_name=\"Neuron\", first_dimension_labels=layer_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topk Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume single layer\n",
    "tokens = [\n",
    "    [\n",
    "        ['Hi', ' and', ' welcome', ' to', ' the', ' topksamples', ' example'], ['This', ' is', ' another', ' example', ' of', ' colored', ' tokens'], ['Yet', ' another', ' example', ' of', ' colored', ' tokens']\n",
    "    ],\n",
    "    [\n",
    "        ['And', ' here', ' another', ' example', ' of', ' colored', ' tokens', ' with', ' more', ' words.'], ['This', ' is', ' another', ' example', ' of', ' tokens.'], ['Again', ', ', ' another', ' example', ' of', ' colored', ' tokens']\n",
    "    ],\n",
    "    [\n",
    "        ['Another', ' example', ' of', ' something', ' of', ' colored', ' tokens', ' with', ' more', ' words.'], ['Weee', ' is', ' another', ' example', ' of', ' tokens.'], ['Once', ' again', ' another', ' example', ' of', ' colored', ' tokens']\n",
    "    ]\n",
    "]  # list of samples for the layer (n_neurons (3), samples (3), tokens (varied))\n",
    "activations = []\n",
    "for neuron in range(len(tokens)):\n",
    "    neuron_acts = []\n",
    "    \n",
    "    for k in range(len(tokens[0])):\n",
    "        acts = (np.random.normal(size=(len(tokens[neuron][k]))) * 5).tolist()\n",
    "        neuron_acts.append(acts)\n",
    "    activations.append(neuron_acts)\n",
    "    \n",
    "# Assume we have an arbitrary selection of neurons\n",
    "neuron_labels = [2, 7, 9]\n",
    "# Wrap tokens and activations in an outer list to represent the single layer\n",
    "topk_samples(tokens=[tokens], activations=[activations], zeroth_dimension_name=\"Layer\", first_dimension_name=\"Neuron\", first_dimension_labels=neuron_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import circuitsvis.sae as sae # Or: from circuitsvis.sae import sae_vis\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Sample Data\n",
    "tokens_sae = [\"The\", \" quick\", \" brown\", \" fox\", \" jumps\", \" over\", \" the\", \" soph\", \"isticated\", \".\"]\n",
    "num_tokens_sae = len(tokens_sae)\n",
    "num_features_sae = 50\n",
    "\n",
    "# Generate random feature activations (replace with your actual SAE activations)\n",
    "np.random.seed(42)\n",
    "feature_activations_sae_np = np.random.rand(num_tokens_sae, num_features_sae) * 20 # Example range\n",
    "# Make some activations zero or negative for variety\n",
    "feature_activations_sae_np[np.random.rand(*feature_activations_sae_np.shape) > 0.2] = 0\n",
    "feature_activations_sae_np[np.random.rand(*feature_activations_sae_np.shape) > 0.95] -= 0\n",
    "\n",
    "\n",
    "# Generate simple feature labels (replace with meaningful labels if available)\n",
    "feature_labels_sae = [f\"Feature {i}\" for i in range(num_features_sae)]\n",
    "\n",
    "print(\"Tokens:\", tokens_sae)\n",
    "print(\"Activations Shape:\", feature_activations_sae_np.shape)\n",
    "print(\"Labels Count:\", len(feature_labels_sae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Usage\n",
    "\n",
    "Call `sae_vis` with the list of tokens, the activation matrix (as NumPy array, PyTorch tensor, or list of lists), and feature labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae.sae_vis(\n",
    "    tokens=tokens_sae,\n",
    "    feature_activations=torch.tensor(feature_activations_sae_np),\n",
    "    feature_labels=feature_labels_sae,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customization\n",
    "\n",
    "Customize the initial view, thresholds, and colors:\n",
    "- `initial_ranking_metric`: 'max' (default), 'l1' (mean abs), 'l0' (non-zero count)\n",
    "- `activation_threshold`: Value below which activations are dimmed/ignored in tooltips.\n",
    "- `color_map`: Colormap name (e.g., 'viridis', 'coolwarm', 'plasma', 'magma').\n",
    "- `num_top_features_overall`: How many features to show in the ranked list.\n",
    "- `num_top_features_per_token`: How many features to show in the token tooltip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = sae.sae_vis(\n",
    "    tokens=tokens_sae,\n",
    "    feature_activations=feature_activations_sae_np,\n",
    "    feature_labels=feature_labels_sae,\n",
    "    initial_ranking_metric=\"l1\",        # Rank by mean absolute activation initially\n",
    "    activation_threshold=5.0,           # Dim tokens/ignore features below 5.0\n",
    "    color_map=\"gray\",               # Use a diverging color map\n",
    "    num_top_features_overall=15,        # Show top 15 features in the list\n",
    "    num_top_features_per_token=3        # Show top 3 features in token tooltips\n",
    ")\n",
    "from IPython.display import display\n",
    "display(out)\n",
    "# You can adjust the height value as needed for better visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
